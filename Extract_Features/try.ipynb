{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbf2ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import List, NamedTuple, Optional\n",
    "import numpy\n",
    "import cv2\n",
    "from dataclasses import dataclass\n",
    "\n",
    "def mean_pixel_distance(left: numpy.ndarray, right: numpy.ndarray) -> float:\n",
    "    \"\"\"Return the mean average distance in pixel values between `left` and `right`.\n",
    "    Both `left and `right` should be 2 dimensional 8-bit images of the same shape.\n",
    "    \"\"\"\n",
    "    assert len(left.shape) == 2 and len(right.shape) == 2\n",
    "    assert left.shape == right.shape\n",
    "    num_pixels: float = float(left.shape[0] * left.shape[1])\n",
    "    return (numpy.sum(numpy.abs(left.astype(numpy.int32) - right.astype(numpy.int32))) / num_pixels)\n",
    "\n",
    "\n",
    "def estimated_kernel_size(frame_width: int, frame_height: int) -> int:\n",
    "    \"\"\"Estimate kernel size based on video resolution.\"\"\"\n",
    "    # TODO: This equation is based on manual estimation from a few videos.\n",
    "    # Create a more comprehensive test suite to optimize against.\n",
    "    size: int = 4 + round(math.sqrt(frame_width * frame_height) / 192)\n",
    "    if size % 2 == 0:\n",
    "        size += 1\n",
    "    return size\n",
    "class ContentDetector():\n",
    "    class Components(NamedTuple):\n",
    "        \"\"\"Components that make up a frame's score, and their default values.\"\"\"\n",
    "        delta_hue: float = 1.0\n",
    "        \"\"\"Difference between pixel hue values of adjacent frames.\"\"\"\n",
    "        delta_sat: float = 1.0\n",
    "        \"\"\"Difference between pixel saturation values of adjacent frames.\"\"\"\n",
    "        delta_lum: float = 1.0\n",
    "        \"\"\"Difference between pixel luma (brightness) values of adjacent frames.\"\"\"\n",
    "        delta_edges: float = 1.0\n",
    "        \"\"\"Difference between calculated edges of adjacent frames.\n",
    "        Edge differences are typically larger than the other components, so the detection\n",
    "        threshold may need to be adjusted accordingly.\"\"\"\n",
    "\n",
    "    DEFAULT_COMPONENT_WEIGHTS = Components()\n",
    "    FRAME_SCORE_KEY = 'content_val'\n",
    "    \"\"\"Key in statsfile representing the final frame score after weighed by specified components.\"\"\"\n",
    "    @dataclass\n",
    "    class _FrameData:\n",
    "        \"\"\"Data calculated for a given frame.\"\"\"\n",
    "        hue: numpy.ndarray\n",
    "        \"\"\"Frame hue map [2D 8-bit].\"\"\"\n",
    "        sat: numpy.ndarray\n",
    "        \"\"\"Frame saturation map [2D 8-bit].\"\"\"\n",
    "        lum: numpy.ndarray\n",
    "        \"\"\"Frame luma/brightness map [2D 8-bit].\"\"\"\n",
    "        edges: Optional[numpy.ndarray]\n",
    "        \"\"\"Frame edge map [2D 8-bit, edges are 255, non edges 0]. Affected by `kernel_size`.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        threshold: float = 27.0,\n",
    "        min_scene_len: int = 15,\n",
    "        weights: 'ContentDetector.Components' = DEFAULT_COMPONENT_WEIGHTS,\n",
    "        luma_only: bool = False,\n",
    "        kernel_size: Optional[int] = None,\n",
    "    ):\n",
    "        self._threshold: float = threshold\n",
    "        self._min_scene_len: int = min_scene_len\n",
    "        self._last_scene_cut: Optional[int] = None\n",
    "        self._last_frame: Optional[ContentDetector._FrameData] = None\n",
    "        self._weights: ContentDetector.Components = weights\n",
    "        if luma_only:\n",
    "            self._weights = ContentDetector.LUMA_ONLY_WEIGHTS\n",
    "        self._kernel: Optional[numpy.ndarray] = None\n",
    "        if kernel_size is not None:\n",
    "            print(kernel_size)\n",
    "            if kernel_size < 3 or kernel_size % 2 == 0:\n",
    "                raise ValueError('kernel_size must be odd integer >= 3')\n",
    "            self._kernel = numpy.ones((kernel_size, kernel_size), numpy.uint8)\n",
    "        self._frame_score: Optional[float] = None\n",
    "    def _calculate_frame_score(self, frame_num: int, frame_img: numpy.ndarray) -> float:\n",
    "        \"\"\"Calculate score representing relative amount of motion in `frame_img` compared to\n",
    "        the last time the function was called (returns 0.0 on the first call).\"\"\"\n",
    "        # TODO: Add option to enable motion estimation before calculating score components.\n",
    "        # TODO: Investigate methods of performing cheaper alternatives, e.g. shifting or resizing\n",
    "        # the frame to simulate camera movement, using optical flow, etc...\n",
    "\n",
    "        # Convert image into HSV colorspace.\n",
    "        hue, sat, lum = cv2.split(cv2.cvtColor(frame_img, cv2.COLOR_BGR2HSV))\n",
    "\n",
    "        # Performance: Only calculate edges if we have to.\n",
    "        calculate_edges: bool = (self._weights.delta_edges > 0.0)\n",
    "#                                  or (self.stats_manager is not None)\n",
    "        edges = self._detect_edges(lum) if calculate_edges else None\n",
    "\n",
    "        if self._last_frame is None:\n",
    "            # Need another frame to compare with for score calculation.\n",
    "            self._last_frame = ContentDetector._FrameData(hue, sat, lum, edges)\n",
    "            return 0.0\n",
    "\n",
    "        score_components = ContentDetector.Components(\n",
    "            delta_hue=mean_pixel_distance(hue, self._last_frame.hue),\n",
    "            delta_sat=mean_pixel_distance(sat, self._last_frame.sat),\n",
    "            delta_lum=mean_pixel_distance(lum, self._last_frame.lum),\n",
    "            delta_edges=(0.0 if edges is None else mean_pixel_distance(\n",
    "                edges, self._last_frame.edges)),\n",
    "        )\n",
    "#         print(score_components.delta_edges)\n",
    "#         print(score_components.delta_hue)\n",
    "#         print(score_components.delta_sat)\n",
    "#         print(score_components.delta_lum)\n",
    "        \n",
    "\n",
    "        frame_score: float = (\n",
    "            sum(component * weight for (component, weight) in zip(score_components, self._weights))\n",
    "            / sum(abs(weight) for weight in self._weights))\n",
    "\n",
    "#         # Record components and frame score if needed for analysis.\n",
    "#         if self.stats_manager is not None:\n",
    "#             metrics = {self.FRAME_SCORE_KEY: frame_score}\n",
    "#             metrics.update(score_components._asdict())\n",
    "#             self.stats_manager.set_metrics(frame_num, metrics)\n",
    "\n",
    "        # Store all data required to calculate the next frame's score.\n",
    "        self._last_frame = ContentDetector._FrameData(hue, sat, lum, edges)\n",
    "        return frame_score\n",
    "    def process_frame(self, frame_num: int, frame_img: numpy.ndarray) -> List[int]:\n",
    "        \"\"\" Similar to ThresholdDetector, but using the HSV colour space DIFFERENCE instead\n",
    "        of single-frame RGB/grayscale intensity (thus cannot detect slow fades with this method).\n",
    "        Arguments:\n",
    "            frame_num: Frame number of frame that is being passed.\n",
    "            frame_img: Decoded frame image (numpy.ndarray) to perform scene\n",
    "                detection on. Can be None *only* if the self.is_processing_required() method\n",
    "                (inhereted from the base SceneDetector class) returns True.\n",
    "        Returns:\n",
    "            List of frames where scene cuts have been detected. There may be 0\n",
    "            or more frames in the list, and not necessarily the same as frame_num.\n",
    "        \"\"\"\n",
    "        if frame_img is None:\n",
    "            # TODO(v0.6.2): Make frame_img a required argument in the interface. Log a warning\n",
    "            # that passing None is deprecated and results will be incorrect if this is the case.\n",
    "            return []\n",
    "\n",
    "        # Initialize last scene cut point at the beginning of the frames of interest.\n",
    "        if self._last_scene_cut is None:\n",
    "            self._last_scene_cut = frame_num\n",
    "\n",
    "        self._frame_score = self._calculate_frame_score(frame_num, frame_img)\n",
    "        if self._frame_score is None:\n",
    "            return []\n",
    "\n",
    "        # We consider any frame over the threshold a new scene, but only if\n",
    "        # the minimum scene length has been reached (otherwise it is ignored).\n",
    "        if self._frame_score >= self._threshold and (\n",
    "            (frame_num - self._last_scene_cut) >= self._min_scene_len):\n",
    "            self._last_scene_cut = frame_num\n",
    "            return [frame_num]\n",
    "\n",
    "        return []\n",
    "\n",
    "\n",
    "    #def post_process(self, frame_num):\n",
    "    #    \"\"\"\n",
    "    #    return []\n",
    "\n",
    "    def _detect_edges(self, lum: numpy.ndarray) -> numpy.ndarray:\n",
    "        \"\"\"Detect edges using the luma channel of a frame.\n",
    "        Arguments:\n",
    "            lum: 2D 8-bit image representing the luma channel of a frame.\n",
    "        Returns:\n",
    "            2D 8-bit image of the same size as the input, where pixels with values of 255\n",
    "            represent edges, and all other pixels are 0.\n",
    "        \"\"\"\n",
    "        # Initialize kernel.\n",
    "        if self._kernel is None:\n",
    "            kernel_size = estimated_kernel_size(lum.shape[1], lum.shape[0])\n",
    "            self._kernel = numpy.ones((kernel_size, kernel_size), numpy.uint8)\n",
    "\n",
    "        # Estimate levels for thresholding.\n",
    "        # TODO(v0.6.2): Add config file entries for sigma, aperture/kernel size, etc.\n",
    "        sigma: float = 1.0 / 3.0\n",
    "        median = numpy.median(lum)\n",
    "        low = int(max(0, (1.0 - sigma) * median))\n",
    "        high = int(min(255, (1.0 + sigma) * median))\n",
    "\n",
    "        # Calculate edges using Canny algorithm, and reduce noise by dilating the edges.\n",
    "        edges = cv2.Canny(lum, low, high)\n",
    "        return cv2.dilate(edges, self._kernel)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "419c2282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "33.18541666666667\n",
      "1.2998090277777778\n",
      "8.558784722222223\n",
      "3.9727430555555556\n",
      "[]\n",
      "35.434375\n",
      "1.7501909722222222\n",
      "11.72734375\n",
      "4.88921875\n",
      "[]\n",
      "45.9796875\n",
      "2.1058333333333334\n",
      "12.57451388888889\n",
      "6.944930555555556\n",
      "[]\n",
      "36.43046875\n",
      "2.777621527777778\n",
      "12.137829861111111\n",
      "5.696944444444444\n",
      "[]\n",
      "37.475260416666664\n",
      "2.3113020833333335\n",
      "12.021041666666667\n",
      "6.950138888888889\n",
      "[]\n",
      "36.09401041666667\n",
      "2.0861631944444445\n",
      "11.953559027777779\n",
      "5.950659722222222\n",
      "[]\n",
      "36.35078125\n",
      "2.036302083333333\n",
      "11.657222222222222\n",
      "6.266944444444444\n",
      "[]\n",
      "46.04609375\n",
      "3.6606770833333333\n",
      "16.169288194444444\n",
      "11.983732638888888\n",
      "[]\n",
      "32.096354166666664\n",
      "3.3726909722222222\n",
      "12.944114583333333\n",
      "9.02576388888889\n",
      "[]\n",
      "25.22109375\n",
      "3.8036631944444443\n",
      "12.42078125\n",
      "6.284704861111111\n",
      "[]\n",
      "26.079947916666665\n",
      "4.142413194444444\n",
      "14.43517361111111\n",
      "8.049149305555556\n",
      "[]\n",
      "21.506770833333334\n",
      "2.923107638888889\n",
      "13.772048611111112\n",
      "8.118402777777778\n",
      "[]\n",
      "21.10390625\n",
      "2.577378472222222\n",
      "12.543975694444445\n",
      "7.284288194444445\n",
      "[]\n",
      "16.557291666666668\n",
      "2.564670138888889\n",
      "11.129947916666667\n",
      "5.257118055555556\n",
      "[]\n",
      "20.298177083333332\n",
      "2.2869270833333335\n",
      "11.137447916666666\n",
      "7.203576388888889\n",
      "[]\n",
      "16.80078125\n",
      "2.159097222222222\n",
      "10.842881944444445\n",
      "5.459184027777778\n",
      "[]\n",
      "128.70859375\n",
      "77.745\n",
      "65.19269097222222\n",
      "66.89026041666666\n",
      "[170]\n",
      "11.492708333333333\n",
      "7.2536805555555555\n",
      "10.610190972222222\n",
      "4.428993055555556\n",
      "[]\n",
      "11.452864583333334\n",
      "5.9975\n",
      "7.447291666666667\n",
      "4.426996527777778\n",
      "[]\n",
      "11.652083333333334\n",
      "6.339149305555556\n",
      "6.877864583333333\n",
      "3.532673611111111\n",
      "[]\n",
      "14.445572916666666\n",
      "8.448645833333334\n",
      "14.963315972222222\n",
      "10.553680555555555\n",
      "[]\n",
      "14.507552083333334\n",
      "8.270451388888889\n",
      "17.075243055555557\n",
      "11.73234375\n",
      "[]\n",
      "14.334895833333333\n",
      "11.363871527777778\n",
      "20.31751736111111\n",
      "12.586770833333333\n",
      "[]\n",
      "22.011458333333334\n",
      "10.890208333333334\n",
      "20.496076388888888\n",
      "13.266145833333333\n",
      "[]\n",
      "25.336197916666666\n",
      "14.673871527777777\n",
      "21.447413194444444\n",
      "13.271354166666667\n",
      "[]\n",
      "25.694791666666667\n",
      "15.922222222222222\n",
      "18.25800347222222\n",
      "9.417256944444444\n",
      "[]\n",
      "34.265625\n",
      "18.891631944444445\n",
      "21.5059375\n",
      "16.559166666666666\n",
      "[]\n",
      "35.78854166666667\n",
      "17.89734375\n",
      "21.990850694444443\n",
      "16.078680555555554\n",
      "[]\n",
      "23.596354166666668\n",
      "13.655017361111112\n",
      "18.200572916666665\n",
      "10.05654513888889\n",
      "[]\n",
      "22.786197916666666\n",
      "12.937881944444445\n",
      "19.30128472222222\n",
      "10.06828125\n",
      "[]\n",
      "16.942447916666666\n",
      "11.561388888888889\n",
      "14.5753125\n",
      "7.318229166666667\n",
      "[]\n",
      "12.435677083333333\n",
      "11.401006944444445\n",
      "15.055034722222222\n",
      "8.16420138888889\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Set the video file path\n",
    "video_path = \"try.mp4\"\n",
    "\n",
    "# Set the output directory for the frames\n",
    "output_dir = \"frames\"\n",
    "\n",
    "# Set the sampling rate (number of frames to skip between extractions)\n",
    "sampling_rate = 10\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# declare object from class \n",
    "video_try = ContentDetector()\n",
    "\n",
    "# Get the total number of frames in the video\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Loop through the frames and extract the sampled frames\n",
    "for frame_idx in range(0, total_frames, sampling_rate):\n",
    "    # Set the frame index to extract\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "\n",
    "    # Read the frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame was successfully read\n",
    "    if ret:\n",
    "        # Construct the output file path for the frame\n",
    "        output_path = os.path.join(output_dir, \"frame_{:06d}.jpg\".format(frame_idx))\n",
    "\n",
    "        # Write the frame to the output file\n",
    "        cv2.imwrite(output_path, frame)\n",
    "    print(video_try.process_frame(frame_idx,frame))\n",
    "    \n",
    "# Release the video capture object\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90ef238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
