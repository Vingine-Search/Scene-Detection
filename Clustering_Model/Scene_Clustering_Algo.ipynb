{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9bc8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.append('../Extract_Features')\n",
    "# from ipynb.fs.full.<visual_2.ipynb> import *\n",
    "import import_ipynb\n",
    "# import_ipynb.sys.path.append('../Extract_Features/visual_2.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da1f11a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from dataclasses import dataclass,fields\n",
    "from utils import *\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb2f0240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: convert_video_to_frames\n",
    "\"\"\"\n",
    "params : video name \n",
    "return : create output directory include the frames of this video \n",
    "\"\"\"\n",
    "def convert_video_to_frames(video_name):\n",
    "    video_path = \"../Dataset/\"+video_name\n",
    "    output_dir = \"../Dataset/frames\"+video_name\n",
    "    # may be changed\n",
    "    sampling_rate = 60\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    for frame_idx in range(0, total_frames, sampling_rate):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            output_path = os.path.join(output_dir, \"frame_{:06d}.jpg\".format(frame_idx))\n",
    "            cv2.imwrite(output_path, frame)\n",
    "    cap.release()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4973cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create classes \n",
    "\"\"\"\n",
    "desc: Difference between pixel hue,saturation,luma,edges values of adjacent frames.\n",
    "\"\"\"\n",
    "from typing import Optional\n",
    "@dataclass\n",
    "class delta_feature:\n",
    "    # by default set all weights to 1\n",
    "    delta_hue: float = 1.0\n",
    "    delta_sat: float = 1.0\n",
    "    delta_lum: float = 1.0\n",
    "    # TODO: have bigger values that other features,detection threshold may need to be adjusted\n",
    "    delta_edges: float = 1.0  \n",
    "\n",
    "\"\"\"\n",
    "desc: features calculated for each frame\n",
    "\"\"\"\n",
    "@dataclass\n",
    "class frame_data:\n",
    "    hue: np.ndarray\n",
    "    sat: np.ndarray\n",
    "    lum: np.ndarray\n",
    "    edges: Optional[np.ndarray]\n",
    "    hsv_hist: Optional[np.ndarray]\n",
    "    # TODO: add optical flow\n",
    "\n",
    "# create defualt weights \n",
    "default_delta_feature_weights = delta_feature()\n",
    "@dataclass\n",
    "class shot_detector:\n",
    "    threshold: float = 27.0\n",
    "    threshold_hist: float = 0.6\n",
    "    min_scene_len: int = 15\n",
    "    weights: 'delta_feature' = default_delta_feature_weights\n",
    "    kernel_size: Optional[int] = None\n",
    "    last_frame: Optional[frame_data] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57dda213",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Detect edges  in the frame \n",
    "    params:\n",
    "        lum:  the luma channel of a frame.\n",
    "        kernel: kernel size \n",
    "    return:\n",
    "        2D 8-bit image where 255--> edge , 0--> other \n",
    "\"\"\"\n",
    "import math\n",
    "def detect_edges(lum: np.ndarray,kernel:int =None) -> np.ndarray:\n",
    "    if kernel == None:\n",
    "        # calculate kernel size  depend on the video reselution\n",
    "        kernel_size = 4 + round(math.sqrt(lum.shape[1]*lum.shape[0]) / 192)\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1\n",
    "        kernel = np.ones((kernel_size, kernel_size), np.uint8) \n",
    "    # Estimate levels for thresholding.\n",
    "    sigma: float = 1.0 / 3.0\n",
    "    median = np.median(lum)\n",
    "    low = int(max(0, (1.0 - sigma) * median))\n",
    "    high = int(min(255, (1.0 + sigma) * median))\n",
    "    # Calculate edges using Canny algorithm, and reduce noise by dilating the edges.\n",
    "    # TODO : Implement  Canny \n",
    "    edges = cv2.Canny(lum, low, high)\n",
    "    return cv2.dilate(edges,kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f46f4389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: get_HSV_feature_frame\n",
    "\"\"\"\n",
    "params : frame\n",
    "return : feature matrix with 3 histograms for H S V\n",
    "\"\"\"\n",
    "def get_HSV_feature_frame(frame):\n",
    "    \n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    hist_frame = cv2.calcHist(frame, [0, 1, 2], None, [256, 256, 256], [0, 256, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist_frame, hist_frame, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "\n",
    "    return hist_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b322133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calcOpticalFlow_feature_frame(frame_pre:np.ndarray, frame:np.ndarray):\n",
    "    # Compute optical flow and histogram of magnitudes\n",
    "    rgb1 = cv2.cvtColor(frame_pre, cv2.COLOR_HSV2RGB)\n",
    "    gray1 = cv2.cvtColor(rgb1, cv2.COLOR_RGB2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    mag_hist, bins = np.histogram(mag.ravel(), 16, [0, 256])\n",
    "    mag_hist_norm = mag_hist.astype(\"float\") / mag_hist.sum()\n",
    "    return mag_hist_norm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0a47d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "calculate fram score , to compare with the threshold and know if it is shot boundry or not \n",
    "params\n",
    " frame_num: index of the frame \n",
    " frame_img: frame itself\n",
    "return \n",
    " frame_score: score for the frame to determine it's boundry or not \n",
    " hist_def:    corelation between the hist of the surrent and prev frame \n",
    "\"\"\"\n",
    "def calculate_frame_score(video_param: shot_detector, frame_img: np.ndarray) -> float:\n",
    "    \n",
    "    # convert image into HSV colorspace\n",
    "    hue, sat, lum = cv2.split(cv2.cvtColor(frame_img, cv2.COLOR_BGR2HSV))\n",
    "\n",
    "    # calculate edges \n",
    "    edges = detect_edges(lum) \n",
    "    \n",
    "    # calculate histogram for H S V values \n",
    "    hist_hsv = get_HSV_feature_frame(frame_img)\n",
    "\n",
    "\n",
    "    if video_param.last_frame is None:\n",
    "        video_param.last_frame = frame_data(hue, sat, lum, edges,hist_hsv)\n",
    "        return 0.0,1.0\n",
    "    \n",
    "\n",
    "    # # calculate histogram for calcOpticalFlow\n",
    "    # hist_optical = get_calcOpticalFlow_feature_frame([video_param.last_frame.hue, video_param.last_frame.sat, video_param.last_frame.lum], frame_img)\n",
    "    \n",
    "    #TODO: calculate HOG\n",
    "    \n",
    "    # get score for adjecent frames \n",
    "    score_components = delta_feature(\n",
    "        delta_hue=mean_pixel_distance(hue, video_param.last_frame.hue),\n",
    "        delta_sat=mean_pixel_distance(sat, video_param.last_frame.sat),\n",
    "        delta_lum=mean_pixel_distance(lum, video_param.last_frame.lum),\n",
    "        delta_edges=(0.0 if edges is None else mean_pixel_distance(\n",
    "            edges, video_param.last_frame.edges)),\n",
    "    )\n",
    "\n",
    "    hist_def = hist_compare(hist_hsv,video_param.last_frame.hsv_hist)\n",
    "\n",
    "    frame_score: float = (\n",
    "        sum(\n",
    "            getattr(score_components, field.name) * getattr(video_param.weights, field.name)\n",
    "            for field in fields(delta_feature)\n",
    "        )\n",
    "        / sum(abs(getattr(video_param.weights, field.name)) for field in fields(delta_feature)))\n",
    "    \n",
    "    # Store all data required to calculate the next frame's score.\n",
    "    video_param.last_frame = frame_data(hue, sat, lum, edges,hist_hsv)\n",
    "    return frame_score,hist_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67411729",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "return: List of frames where scene cuts have been detected\n",
    "\"\"\"\n",
    "def process_frame(\n",
    "    video_param: shot_detector, frames_since_last_cut: List[frame_data],\n",
    "    frames_count_since_last_cut: int, frame_img: np.ndarray, op) -> Tuple[Optional[float], frame_data]:\n",
    "    \"\"\"Returns the shot representation/embeddings (by performing `op`) for a span of frames\n",
    "    if `frame_img` is a boundary, None otherwise.\n",
    "    Also returns the `frame_data` for `frame_img` to be used by the caller.\n",
    "    \"\"\"\n",
    "    frame_score ,hist_def= calculate_frame_score(video_param, frame_img)\n",
    "    # consider any frame over the threshold a new scene, but only if\n",
    "    # the minimum scene length has been reached (otherwise it is ignored).\n",
    "    # NOTE: `frames_count_since_last_cut` is the actual number of frames since the last cut, i.e. not sampled every x frames.\n",
    "\n",
    "    if frames_count_since_last_cut < video_param.min_scene_len:\n",
    "        return (None, video_param.last_frame,hist_def)\n",
    "    ##################################################################################################\n",
    "    # try use the histograme of the boundary not the avg of the frames \n",
    "    shot_score = op(frames_since_last_cut) if frame_score >= video_param.threshold else None\n",
    "    return (shot_score, video_param.last_frame,hist_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db9573d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_frames_features(frames: List[frame_data]) -> frame_data:\n",
    "    \"\"\"A reduction operation to perform (averaging) on a list of frame data.\n",
    "    The reduced data would then be used as a representation of the whole shot.\n",
    "    \"\"\"\n",
    "    assert frames, \"Operation can not be performed on 0 frames\"\n",
    "    avg_frame_data = frame_data(0, 0, 0, None)\n",
    "    count = len(frames)\n",
    "    attrs = [f.name for f in fields(frames[0])]\n",
    "    for attr_name in attrs:\n",
    "        attr_value = sum(getattr(frame, attr_name) for frame in frames) / count\n",
    "        setattr(avg_frame_data, attr_name, attr_value)\n",
    "    return avg_frame_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bffe1562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_framesboundary_data():\n",
    "    video_path = \"../Dataset/tears_of_steel_1080p.mov\"\n",
    "    output_dir = \"../Dataset/frames\"\n",
    "    #TODO: sampling_rate should be changed \n",
    "    sampling_rate = 60\n",
    "    frame_idx_list = []\n",
    "    boundary_frames: List[frame_data] = []\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    video_try = shot_detector()\n",
    "    # assert video_try.min_scene_len > sampling_rate, \"The sampling rate is must be strictly less than the minimum scene length\"\n",
    "    \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_data_since_last_cut = []\n",
    "    \n",
    "    for frame_idx in range(0, total_frames, sampling_rate):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            output_path = os.path.join(output_dir, \"frame_{:06d}.jpg\".format(frame_idx))\n",
    "            cv2.imwrite(output_path, frame)\n",
    "    \n",
    "        shot_score, data,hist_def = process_frame(\n",
    "            video_try, frame_data_since_last_cut,\n",
    "            len(frame_data_since_last_cut) * sampling_rate,\n",
    "            frame, avg_frames_features)\n",
    "        # if shot_score is not None:\n",
    "        #     print(frame_idx)\n",
    "        #     # Reset the data accumulator.\n",
    "        #     frame_data_since_last_cut = []\n",
    "        # frame_data_since_last_cut.append(data)\n",
    "        if hist_def < video_try.threshold_hist:\n",
    "            print(frame_idx)\n",
    "            boundary_frames.append((data,frame_idx))\n",
    "    cap.release()\n",
    "    return boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fd03681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get_distance_matrix \n",
    "\"\"\"\n",
    "params : \n",
    " feature_vector: array of feature vectors for each shot \n",
    "return : 2D distance matrix (Matrix 2D with size N*N ,N is the numer of shots,cell (i,j) have the feature distance between i,j shots)\n",
    "\"\"\"\n",
    "features_matrix =  np.array([[2, 1, 0, 4, 1], [0, 3, 1, 1, 10],[1, 1, 0, 1, 0]])\n",
    "def get_distance_matrix(features_matrix):\n",
    "    D_Matrix = sparse.csr_matrix(features_matrix)\n",
    "    D_Matrix = cosine_similarity(D_Matrix)\n",
    "    D_Matrix = 1-D_Matrix\n",
    "    # D_Matrix.tolist()\n",
    "    return D_Matrix\n",
    "\n",
    "#TODO: try eculedian  distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db7d560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "params : \n",
    "boundary_frames : frames classified to be boundaries thsi is list of tuples (data, frame index)\n",
    "return : 2D distance matrix (Matrix 2D with size N*N ,N is the numer of shots,cell (i,j) have the feature distance between i,j shots)\n",
    "\"\"\"\n",
    "def get_distance_matrix(boundary_frames):\n",
    "    num_shots = len(boundary_frames)\n",
    "    dist_matrix = np.zeros((num_shots, num_shots))\n",
    "    for i in range(num_shots):\n",
    "        print(\"i\",i)\n",
    "        for j in range(i, num_shots):\n",
    "            if i == j:\n",
    "                dist_matrix[i, j] = 0\n",
    "            else:\n",
    "                # compute the distance between the i-th and j-th shots' histograms\n",
    "                dist: float =cv2.compareHist(boundary_frames[i][0].hsv_hist, boundary_frames[j][0].hsv_hist, cv2.HISTCMP_CORREL)\n",
    "                print(dist)\n",
    "                dist_matrix[i, j] = 1.0- dist\n",
    "                dist_matrix[j, i] = 1.0- dist\n",
    "    return dist_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e675f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D_Matrix = get_distance_matrix(features_matrix)\n",
    "# print(D_Matrix)\n",
    "# print(1-D_Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "399dc23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"get the total sum of distance of different segmentation \n",
    "params :\n",
    " Distance_Matrix: 2D distance matrix \n",
    " N: number of shots \n",
    "return : table with all different segments in D_Matrix\n",
    "\"\"\"\n",
    "def get_internal_sums(D_Matrix,N):\n",
    "    # D_sum = torch.zeros(N,N, device=self.device)\n",
    "    D_sum = np.zeros(shape=(N,N))\n",
    "    # initialize diagonal \n",
    "    for shot_index in range(N):\n",
    "        D_sum[shot_index,shot_index] = D_Matrix[shot_index,shot_index]\n",
    "    # # initialize second diagonal\n",
    "    # for shot_index in range(0, N-1):\n",
    "    #     D_sum[shot_index, shot_index+1] = D_Matrix[shot_index:shot_index+1+1, shot_index:shot_index+1+1].sum()\n",
    "    #     print(D_sum[shot_index, shot_index+1])\n",
    "    #     # TODO: recheck this condition \n",
    "    #     D_sum[shot_index+1, shot_index] = D_sum[shot_index, shot_index+1]\n",
    "    #     print(D_sum[shot_index+1, shot_index])\n",
    "    #TODO: if you change the 1 to 2 you should discomment the above code \n",
    "    for scene_size in range(1, N):\n",
    "        for start_shot in range(0, N - scene_size):\n",
    "            '''\n",
    "            D_sum[i,j] =+D_sum[i-1,j]                  --> missing last row\n",
    "                        +D_sum[i,j-1]                  --> missing last column \n",
    "                        -D_sum[i-1,j-1]                --> as we sum it twice before\n",
    "                        +D_Matrix[i,j] + D_Matrix[j,i] -->missing cells in brevious calculations  \n",
    "            '''\n",
    "            D_sum[start_shot, start_shot + scene_size] = D_sum[start_shot, start_shot + scene_size - 1] + D_sum[start_shot - 1, start_shot + scene_size] - D_sum[start_shot - 1, start_shot + scene_size - 1] +  D_Matrix[start_shot, start_shot + scene_size] + D_Matrix[start_shot + scene_size, start_shot] \n",
    "            # as the matrix is symetric \n",
    "            D_sum[start_shot + scene_size, start_shot] = D_sum[start_shot, start_shot + scene_size]\n",
    "    return D_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e5b6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "# TODO: hierarchical clustering_h_add\n",
    "# TODO: NOW I AM WORKING WITHOUT USING INTERMEDIATE SUMS (I SHOULD USE IT LATER FOR EFFECIENCY)\n",
    "\"\"\"params : \n",
    "    D_matrix : 2D distance matrix (with size N*N)\n",
    "    scenes_num: Nuber of scenes needed to be generated \n",
    "return : T (T is the optimal shot indexes where thw shots are devided into scenes)\n",
    "\"\"\"\n",
    "def get_optimal_sequence_add1(D_matrix, scenes_num):\n",
    "    N = D_matrix.shape[0]\n",
    "    print(N)\n",
    "    '''\n",
    "    define cost matrix to define the optimal objective function value ,the optimal one is then cost_Matrix[1,scenes_num]\n",
    "    cost_Matrix[n,scenes_num] means the cost of deviding  N-n+1 shots to scenes_num scenes\n",
    "    '''\n",
    "    cost_Matrix = np.zeros((N, scenes_num))\n",
    "    print(cost_Matrix.shape)\n",
    "    boundry_index_Matrix = np.zeros((N, scenes_num), dtype=int)\n",
    "\n",
    "    # initialization\n",
    "    for n in range(0, N):\n",
    "        cost_Matrix[n, 0] = np.sum(D_matrix[n:, n:])\n",
    "    \n",
    "    for n in range(0, N):\n",
    "        boundry_index_Matrix[n, 0] = N - 1\n",
    "\n",
    "    # build the rest of the table \n",
    "    for k in range(1,scenes_num):\n",
    "        for n in range(0,N):\n",
    "            diffrent_scene_costs = []\n",
    "            # define i the index of the next boundry will be betwen (n,N)\n",
    "            for i in range(n, N):\n",
    "                if i < N - 1:\n",
    "                    C_prev = cost_Matrix[i + 1, k - 1]\n",
    "                else:\n",
    "                    C_prev = 0\n",
    "                scene_cost = np.sum(D_matrix[n:i + 1, n:i + 1])\n",
    "                scene_cost = scene_cost + C_prev\n",
    "                diffrent_scene_costs.append((scene_cost,i))\n",
    "            # diffrent_scene_costs = np.array(diffrent_scene_costs)\n",
    "            # choose the minimum value that we can put i and achieve the least cost for the scene \n",
    "            # cost_Matrix[n, k] = np.min(diffrent_scene_costs)\n",
    "            min_cost = min(diffrent_scene_costs, key=itemgetter(0))\n",
    "            cost_Matrix[n, k] = min_cost[0]\n",
    "            # save the index\n",
    "            # boundry_index_Matrix[n, k] = np.where(diffrent_scene_costs == cost_Matrix[n, k])[0][0] + n\n",
    "            boundry_index_Matrix[n, k] = min_cost[0]+n\n",
    "    \n",
    "    scene_boundries = np.zeros((scenes_num,), dtype=int)\n",
    "    scene_boundries_prev = 0\n",
    "    for i in range(0, scenes_num):\n",
    "        if i == 0:\n",
    "            scene_boundries_prev = 0\n",
    "        else:\n",
    "            scene_boundries_prev = scene_boundries[i - 1]\n",
    "        print(scene_boundries_prev)\n",
    "        print(scenes_num - i - 1)\n",
    "        scene_boundries[i] = boundry_index_Matrix[scene_boundries_prev, scenes_num - i - 1]\n",
    "    return scene_boundries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46af60e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "300\n",
      "360\n",
      "420\n",
      "480\n",
      "600\n",
      "1020\n",
      "1140\n",
      "1200\n",
      "1260\n",
      "1320\n",
      "1380\n",
      "1440\n",
      "1560\n",
      "1680\n",
      "1800\n",
      "1920\n",
      "1980\n",
      "2040\n",
      "2220\n",
      "2340\n",
      "2400\n",
      "2460\n",
      "2820\n",
      "3060\n",
      "3240\n",
      "3360\n",
      "3480\n",
      "3540\n",
      "3720\n",
      "4140\n",
      "4560\n",
      "4680\n",
      "4800\n",
      "4860\n",
      "4980\n",
      "5040\n",
      "5100\n",
      "5160\n",
      "5220\n",
      "5280\n",
      "5340\n",
      "5460\n",
      "5640\n",
      "5760\n",
      "6120\n",
      "6240\n",
      "6600\n",
      "6720\n",
      "6960\n",
      "7140\n",
      "7200\n",
      "7260\n",
      "7320\n",
      "7440\n",
      "7500\n",
      "7620\n",
      "7680\n",
      "7740\n",
      "7800\n",
      "7920\n",
      "7980\n",
      "8160\n",
      "8220\n",
      "8340\n",
      "8400\n",
      "8460\n",
      "8520\n",
      "8580\n",
      "8700\n",
      "8760\n",
      "8880\n",
      "8940\n",
      "9000\n",
      "9060\n",
      "9120\n",
      "9180\n",
      "9240\n",
      "9360\n",
      "9600\n",
      "9660\n",
      "9720\n",
      "9840\n",
      "9900\n",
      "9960\n",
      "10080\n",
      "10140\n",
      "10200\n",
      "10260\n",
      "10320\n",
      "10380\n",
      "10440\n",
      "10500\n",
      "10560\n",
      "10620\n",
      "10680\n",
      "11100\n",
      "11160\n",
      "11340\n",
      "11400\n",
      "11520\n",
      "11580\n",
      "11640\n",
      "11700\n",
      "11760\n",
      "11820\n",
      "11880\n",
      "11940\n",
      "12000\n",
      "12060\n",
      "12120\n",
      "12180\n",
      "12240\n",
      "12480\n",
      "12540\n",
      "12660\n",
      "12960\n",
      "13080\n",
      "13320\n",
      "13380\n",
      "13560\n",
      "13740\n",
      "13800\n",
      "14160\n",
      "17040\n",
      "17160\n",
      "17580\n"
     ]
    }
   ],
   "source": [
    "frames_boundary= get_framesboundary_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4a25d29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n"
     ]
    }
   ],
   "source": [
    "print(len(frames_boundary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7caca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix = get_distance_matrix(frames_boundary[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2a72a9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_sum = get_internal_sums(dist_matrix,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "80c29476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_sequence_add2(D_matrix, scenes_num):\n",
    "\n",
    "        shots_num = D_matrix.shape[0]\n",
    "\n",
    "        if shots_num < 1 or scenes_num < 1 or shots_num != D_matrix.shape[1]:\n",
    "            print(\"Error: Problem with input.\")\n",
    "            return []\n",
    "\n",
    "        if scenes_num > shots_num:\n",
    "            print(\"Warning: More scenes than shots. Returning shot boundaries.\")\n",
    "            return np.arrange(1, shots_num + 1)\n",
    "\n",
    "        if scenes_num == 1:\n",
    "            return [shots_num - 1]\n",
    "\n",
    "        D_sum = get_internal_sums(D_matrix,40)\n",
    "\n",
    "        C = np.zeros((shots_num, scenes_num))\n",
    "        I = np.zeros((shots_num, scenes_num))\n",
    "\n",
    "        # initialization\n",
    "        for nn in range(0, shots_num):\n",
    "            C[nn, 0] = D_sum[nn, shots_num - 1]\n",
    "            I[nn, 0] = shots_num - 1\n",
    "\n",
    "        # fill the rest\n",
    "        for kk in range(1, scenes_num):\n",
    "            for nn in range(0, shots_num - kk):\n",
    "                # T will hold the vector in which we're searching for a minimum\n",
    "                T = np.transpose(D_sum[nn, nn:shots_num- kk]) + C[nn + 1:shots_num - kk + 1, kk - 1]\n",
    "                I[nn, kk] = np.argmin(T)\n",
    "                C[nn, kk] = T[int(I[nn, kk])]\n",
    "                I[nn, kk] = I[nn, kk] + nn\n",
    "        # prepare returned boundaries\n",
    "        boundary_locations = np.zeros(scenes_num)\n",
    "        the_prev = -1\n",
    "        for kk in range(0, scenes_num):\n",
    "            boundary_locations[kk] = I[int(the_prev + 1), scenes_num - kk - 1]\n",
    "            the_prev = boundary_locations[kk]\n",
    "        if the_prev != shots_num - 1:\n",
    "            print(\"Warning: Encountered an unknown problem.\")\n",
    "        return boundary_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a909159",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = get_optimal_sequence_add1(dist_matrix, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c34f1618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nparams : 2D distance matrix (with size N*N)\\nreturn : T (T is the optimal shot indexes where thw shots are devided into scenes)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: hierarchical clustering_h_nrm\n",
    "\"\"\"\n",
    "params : 2D distance matrix (with size N*N)\n",
    "return : T (T is the optimal shot indexes where thw shots are devided into scenes)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8a38a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get estimated number of scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2b4a8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_locations = get_optimal_sequence_add2(dist_matrix,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8f1d8bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  2. 10. 39.]\n"
     ]
    }
   ],
   "source": [
    "print(boundary_locations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
